{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c54d6121",
   "metadata": {},
   "source": [
    "# Multilayer Perceptron (MLP) Classification Tutorial / 多層パーセプトロン分類チュートリアル\n",
    "\n",
    "\n",
    "In this tutorial, you will learn:\n",
    "このチュートリアルでは、以下を学習します：\n",
    "\n",
    "- **Nonlinear classification problems** / 非線形分類問題\n",
    "- **Multilayer perceptron architecture** / 多層パーセプトロンアーキテクチャ\n",
    "- **TensorFlow/Keras implementation** / TensorFlow/Keras実装\n",
    "- **Comparison between linear and nonlinear models** / 線形モデルと非線形モデルの比較\n",
    "- **Decision boundary visualization** / 決定境界の可視化\n",
    "\n",
    "\n",
    "While perceptrons can only learn linearly separable patterns, multilayer perceptrons (MLPs) can learn complex nonlinear decision boundaries. This tutorial demonstrates the power of adding hidden layers and nonlinear activation functions.\n",
    "\n",
    "パーセプトロンは線形分離可能なパターンしか学習できませんが、多層パーセプトロン（MLP）は複雑な非線形決定境界を学習できます。このチュートリアルでは、隠れ層と非線形活性化関数を追加することの威力を実証します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e60734c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required libraries / 必要なライブラリをインポート\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Activation\n",
    "\n",
    "np.random.seed(42)\n",
    "\n",
    "print(\"Libraries imported successfully / ライブラリのインポートが完了しました\")\n",
    "print(\"TensorFlow version:\", keras.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b60ecfd5",
   "metadata": {},
   "source": [
    "## Q1: Generate Sinusoidal Boundary Classification Data / 正弦波境界分類データの生成\n",
    "\n",
    "Create a complex nonlinear classification problem where the decision boundary follows a sinusoidal pattern.\n",
    "\n",
    "決定境界が正弦波パターンに従う複雑な非線形分類問題を作成します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b014669",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate nonlinear classification data / 非線形分類データ生成\n",
    "N = 500  # Number of samples / サンプル数\n",
    "\n",
    "x = np.random.uniform(low=-1, high=1, size=(N, 2))\n",
    "y = np.zeros(N)\n",
    "\n",
    "y[x[:, 1] - np.sin(2*np.pi*x[:, 0]) > 0] = 1\n",
    "\n",
    "plt.figure(figsize=(10, 8))\n",
    "plt.plot(x[y==0, 0], x[y==0, 1], 'bo', alpha=0.6, label='Class 0', markersize=6)\n",
    "plt.plot(x[y==1, 0], x[y==1, 1], 'ro', alpha=0.6, label='Class 1', markersize=6)\n",
    "\n",
    "xx = np.linspace(-1, 1, 200)\n",
    "yy = np.sin(2*np.pi*xx)\n",
    "plt.plot(xx, yy, 'g-', linewidth=3, label='True Boundary')\n",
    "\n",
    "plt.xlim(-1, 1)\n",
    "plt.ylim(-1, 1)\n",
    "plt.xlabel('X1')\n",
    "plt.ylabel('X2')\n",
    "plt.title('Nonlinear Classification Problem: Sinusoidal Boundary')\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.show()\n",
    "\n",
    "print(f\"Generated {N} samples with sinusoidal decision boundary\")\n",
    "print(f\"正弦波決定境界を持つ{N}個のサンプルを生成しました\")\n",
    "print(f\"Class 0: {np.sum(y==0)} samples, Class 1: {np.sum(y==1)} samples\")\n",
    "print(f\"クラス0: {np.sum(y==0)}サンプル、クラス1: {np.sum(y==1)}サンプル\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b069d7ad",
   "metadata": {},
   "source": [
    "## Q2: Implement Linear Logistic Regression Baseline / 線形ロジスティック回帰ベースラインの実装\n",
    "\n",
    "First, try to solve the problem with a simple linear model to demonstrate its limitations.\n",
    "\n",
    "まず、シンプルな線形モデルで問題を解決しようとして、その限界を実証します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91d121e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create linear logistic regression model / 線形ロジスティック回帰モデル作成\n",
    "print(\"Training linear logistic regression model...\")\n",
    "print(\"線形ロジスティック回帰モデルを訓練中...\")\n",
    "\n",
    "linear_model = Sequential()\n",
    "linear_model.add(Dense(1, input_shape=(2,), use_bias=True))\n",
    "linear_model.add(Activation('sigmoid'))\n",
    "\n",
    "linear_model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "linear_history = linear_model.fit(x, y, epochs=1000, batch_size=100, verbose=0)\n",
    "\n",
    "print(\"Linear model training completed!\")\n",
    "print(\"線形モデルの訓練が完了しました！\")\n",
    "\n",
    "plt.figure(figsize=(12, 4))\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(linear_history.history['loss'], 'b-', linewidth=2)\n",
    "plt.title('Linear Model: Loss Evolution')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(linear_history.history['accuracy'], 'r-', linewidth=2)\n",
    "plt.title('Linear Model: Accuracy Evolution')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "final_loss = linear_history.history['loss'][-1]\n",
    "final_accuracy = linear_history.history['accuracy'][-1]\n",
    "print(f\"Linear model final loss: {final_loss:.4f}\")\n",
    "print(f\"Linear model final accuracy: {final_accuracy:.4f}\")\n",
    "print(f\"線形モデル最終損失: {final_loss:.4f}\")\n",
    "print(f\"線形モデル最終精度: {final_accuracy:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "511f4924",
   "metadata": {},
   "source": [
    "## Q3: Build MLP Model with TensorFlow/Keras / TensorFlow/KerasによるMLP構築\n",
    "\n",
    "Create a multilayer perceptron with hidden layers to handle the nonlinear classification problem.\n",
    "\n",
    "非線形分類問題を処理するために隠れ層を持つ多層パーセプトロンを作成します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28aea725",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create multilayer perceptron model / 多層パーセプトロンモデル作成\n",
    "print(\"Building multilayer perceptron model...\")\n",
    "print(\"多層パーセプトロンモデルを構築中...\")\n",
    "\n",
    "mlp_model = Sequential()\n",
    "mlp_model.add(Dense(5, input_shape=(2,), use_bias=True))  # Hidden layer with 5 neurons / 5ニューロンの隠れ層\n",
    "mlp_model.add(Activation('relu'))  # ReLU activation for nonlinearity / 非線形性のためのReLU活性化\n",
    "mlp_model.add(Dense(1))  # Output layer / 出力層\n",
    "mlp_model.add(Activation('sigmoid'))  # Sigmoid for binary classification / 二値分類のためのSigmoid\n",
    "\n",
    "mlp_model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "print(\"\\nMLP Model Architecture:\")\n",
    "print(\"MLPモデルアーキテクチャ:\")\n",
    "mlp_model.summary()\n",
    "\n",
    "print(\"\\nMLP model built successfully!\")\n",
    "print(\"MLPモデルの構築が完了しました！\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f02ceb1",
   "metadata": {},
   "source": [
    "## Q4: Train and Compare Models / モデル学習と比較\n",
    "\n",
    "Train the MLP model and compare its performance with the linear baseline.\n",
    "\n",
    "MLPモデルを訓練し、線形ベースラインとの性能を比較します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41ab458b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train MLP model / MLPモデル訓練\n",
    "print(\"Training MLP model...\")\n",
    "print(\"MLPモデルを訓練中...\")\n",
    "\n",
    "mlp_history = mlp_model.fit(x, y, epochs=2000, batch_size=100, verbose=0)\n",
    "\n",
    "print(\"MLP model training completed!\")\n",
    "print(\"MLPモデルの訓練が完了しました！\")\n",
    "\n",
    "plt.figure(figsize=(15, 5))\n",
    "\n",
    "plt.subplot(1, 3, 1)\n",
    "plt.plot(linear_history.history['loss'], 'b-', linewidth=2, label='Linear Model')\n",
    "plt.plot(mlp_history.history['loss'], 'r-', linewidth=2, label='MLP Model')\n",
    "plt.title('Loss Evolution Comparison')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.yscale('log')  # Log scale for better visualization / より良い可視化のための対数スケール\n",
    "\n",
    "plt.subplot(1, 3, 2)\n",
    "plt.plot(linear_history.history['accuracy'], 'b-', linewidth=2, label='Linear Model')\n",
    "plt.plot(mlp_history.history['accuracy'], 'r-', linewidth=2, label='MLP Model')\n",
    "plt.title('Accuracy Evolution Comparison')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "models = ['Linear', 'MLP']\n",
    "final_losses = [linear_history.history['loss'][-1], mlp_history.history['loss'][-1]]\n",
    "final_accuracies = [linear_history.history['accuracy'][-1], mlp_history.history['accuracy'][-1]]\n",
    "\n",
    "plt.subplot(1, 3, 3)\n",
    "x_pos = np.arange(len(models))\n",
    "plt.bar(x_pos, final_accuracies, alpha=0.7, color=['blue', 'red'])\n",
    "plt.xlabel('Model Type')\n",
    "plt.ylabel('Final Accuracy')\n",
    "plt.title('Final Accuracy Comparison')\n",
    "plt.xticks(x_pos, models)\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "for i, acc in enumerate(final_accuracies):\n",
    "    plt.text(i, acc + 0.01, f'{acc:.3f}', ha='center', va='bottom')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"MODEL PERFORMANCE COMPARISON / モデル性能比較\")\n",
    "print(\"=\"*50)\n",
    "print(f\"Linear Model - Loss: {final_losses[0]:.4f}, Accuracy: {final_accuracies[0]:.4f}\")\n",
    "print(f\"MLP Model    - Loss: {final_losses[1]:.4f}, Accuracy: {final_accuracies[1]:.4f}\")\n",
    "print(f\"線形モデル - 損失: {final_losses[0]:.4f}, 精度: {final_accuracies[0]:.4f}\")\n",
    "print(f\"MLPモデル  - 損失: {final_losses[1]:.4f}, 精度: {final_accuracies[1]:.4f}\")\n",
    "print(\"=\"*50)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "333fb0a6",
   "metadata": {},
   "source": [
    "## Q5: Visualize Decision Boundaries / 決定境界の可視化\n",
    "\n",
    "Visualize and compare the decision boundaries learned by both models.\n",
    "\n",
    "両方のモデルが学習した決定境界を可視化し比較します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f0848e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create meshgrid for decision boundary visualization / 決定境界可視化のためのメッシュグリッド作成\n",
    "def create_meshgrid(resolution=200):\n",
    "    \"\"\"Create meshgrid for visualization / 可視化用メッシュグリッド作成\"\"\"\n",
    "    xx = np.linspace(-1, 1, resolution)\n",
    "    yy = np.linspace(-1, 1, resolution)\n",
    "    XX, YY = np.meshgrid(xx, yy)\n",
    "    grid_points = np.hstack((XX.reshape(-1, 1), YY.reshape(-1, 1)))\n",
    "    return XX, YY, grid_points\n",
    "\n",
    "XX, YY, grid_points = create_meshgrid(128)\n",
    "\n",
    "linear_predictions = linear_model.predict(grid_points, verbose=0).reshape(128, 128)\n",
    "mlp_predictions = mlp_model.predict(grid_points, verbose=0).reshape(128, 128)\n",
    "\n",
    "fig, axes = plt.subplots(2, 2, figsize=(15, 12))\n",
    "\n",
    "axes[0, 0].contourf(XX, YY, linear_predictions, levels=50, alpha=0.6, cmap='RdYlBu')\n",
    "axes[0, 0].plot(x[y==0, 0], x[y==0, 1], 'bo', alpha=0.6, markersize=3)\n",
    "axes[0, 0].plot(x[y==1, 0], x[y==1, 1], 'ro', alpha=0.6, markersize=3)\n",
    "axes[0, 0].set_title('Linear Model Decision Boundary')\n",
    "axes[0, 0].set_xlabel('X1')\n",
    "axes[0, 0].set_ylabel('X2')\n",
    "axes[0, 0].grid(True, alpha=0.3)\n",
    "\n",
    "im = axes[0, 1].contourf(XX, YY, mlp_predictions, levels=50, alpha=0.6, cmap='RdYlBu')\n",
    "axes[0, 1].plot(x[y==0, 0], x[y==0, 1], 'bo', alpha=0.6, markersize=3)\n",
    "axes[0, 1].plot(x[y==1, 0], x[y==1, 1], 'ro', alpha=0.6, markersize=3)\n",
    "axes[0, 1].set_title('MLP Model Decision Boundary')\n",
    "axes[0, 1].set_xlabel('X1')\n",
    "axes[0, 1].set_ylabel('X2')\n",
    "axes[0, 1].grid(True, alpha=0.3)\n",
    "\n",
    "plt.colorbar(im, ax=axes[0, 1], label='Prediction Probability')\n",
    "\n",
    "xx_true = np.linspace(-1, 1, 200)\n",
    "yy_true = np.sin(2*np.pi*xx_true)\n",
    "\n",
    "axes[1, 0].plot(x[y==0, 0], x[y==0, 1], 'bo', alpha=0.4, markersize=4, label='Class 0')\n",
    "axes[1, 0].plot(x[y==1, 0], x[y==1, 1], 'ro', alpha=0.4, markersize=4, label='Class 1')\n",
    "axes[1, 0].plot(xx_true, yy_true, 'g-', linewidth=3, label='True Boundary')\n",
    "axes[1, 0].contour(XX, YY, linear_predictions, levels=[0.5], colors='blue', linewidths=2, linestyles='--', label='Linear Boundary')\n",
    "axes[1, 0].set_title('Linear Model vs True Boundary')\n",
    "axes[1, 0].set_xlabel('X1')\n",
    "axes[1, 0].set_ylabel('X2')\n",
    "axes[1, 0].legend()\n",
    "axes[1, 0].grid(True, alpha=0.3)\n",
    "\n",
    "axes[1, 1].plot(x[y==0, 0], x[y==0, 1], 'bo', alpha=0.4, markersize=4, label='Class 0')\n",
    "axes[1, 1].plot(x[y==1, 0], x[y==1, 1], 'ro', alpha=0.4, markersize=4, label='Class 1')\n",
    "axes[1, 1].plot(xx_true, yy_true, 'g-', linewidth=3, label='True Boundary')\n",
    "axes[1, 1].contour(XX, YY, mlp_predictions, levels=[0.5], colors='red', linewidths=2, linestyles='--', label='MLP Boundary')\n",
    "axes[1, 1].set_title('MLP Model vs True Boundary')\n",
    "axes[1, 1].set_xlabel('X1')\n",
    "axes[1, 1].set_ylabel('X2')\n",
    "axes[1, 1].legend()\n",
    "axes[1, 1].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "linear_train_pred = (linear_model.predict(x, verbose=0) > 0.5).astype(int).flatten()\n",
    "mlp_train_pred = (mlp_model.predict(x, verbose=0) > 0.5).astype(int).flatten()\n",
    "\n",
    "linear_errors = np.sum(linear_train_pred != y)\n",
    "mlp_errors = np.sum(mlp_train_pred != y)\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"CLASSIFICATION ERROR ANALYSIS / 分類誤差解析\")\n",
    "print(\"=\"*60)\n",
    "print(f\"Linear Model - Training Errors: {linear_errors}/{len(y)} ({linear_errors/len(y)*100:.1f}%)\")\n",
    "print(f\"MLP Model    - Training Errors: {mlp_errors}/{len(y)} ({mlp_errors/len(y)*100:.1f}%)\")\n",
    "print(f\"線形モデル - 訓練誤差: {linear_errors}/{len(y)} ({linear_errors/len(y)*100:.1f}%)\")\n",
    "print(f\"MLPモデル  - 訓練誤差: {mlp_errors}/{len(y)} ({mlp_errors/len(y)*100:.1f}%)\")\n",
    "print(\"=\"*60)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a5a11d3",
   "metadata": {},
   "source": [
    "## Summary / まとめ\n",
    "\n",
    "In this tutorial, you learned:\n",
    "このチュートリアルでは以下を学習しました：\n",
    "\n",
    "1. **Nonlinear Problems**: How to create and visualize complex classification problems that cannot be solved by linear models\n",
    "   **非線形問題**: 線形モデルでは解決できない複雑な分類問題の作成と可視化方法\n",
    "\n",
    "2. **Linear Limitations**: Why simple linear models fail on nonlinear decision boundaries\n",
    "   **線形の限界**: なぜシンプルな線形モデルが非線形決定境界で失敗するのか\n",
    "\n",
    "3. **MLP Architecture**: How to build multilayer perceptrons with hidden layers and nonlinear activations\n",
    "   **MLPアーキテクチャ**: 隠れ層と非線形活性化を持つ多層パーセプトロンの構築方法\n",
    "\n",
    "4. **TensorFlow/Keras**: Practical implementation of neural networks using modern deep learning frameworks\n",
    "   **TensorFlow/Keras**: 現代の深層学習フレームワークを使用したニューラルネットワークの実践的実装\n",
    "\n",
    "5. **Decision Boundary Visualization**: Techniques to visualize and compare model performance\n",
    "   **決定境界可視化**: モデル性能を可視化し比較する技術\n",
    "\n",
    "6. **Performance Analysis**: How to evaluate and compare different model architectures\n",
    "   **性能解析**: 異なるモデルアーキテクチャの評価と比較方法\n",
    "\n",
    "**Key Insights / 重要な洞察:**\n",
    "\n",
    "- **Linear models** are limited to linear decision boundaries and struggle with complex patterns\n",
    "  **線形モデル**は線形決定境界に限定され、複雑なパターンに苦労します\n",
    "\n",
    "- **MLPs with hidden layers** can approximate complex nonlinear functions and decision boundaries\n",
    "  **隠れ層を持つMLP**は複雑な非線形関数と決定境界を近似できます\n",
    "\n",
    "- **ReLU activation** provides the nonlinearity needed to learn complex patterns\n",
    "  **ReLU活性化**は複雑なパターンを学習するために必要な非線形性を提供します\n",
    "\n",
    "- **Proper visualization** is crucial for understanding model behavior and performance\n",
    "  **適切な可視化**はモデルの動作と性能を理解するために重要です\n",
    "\n",
    "This foundation prepares you for more advanced neural network architectures and deep learning techniques!\n",
    "\n",
    "この基礎により、より高度なニューラルネットワークアーキテクチャと深層学習技術への準備が整います！"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
