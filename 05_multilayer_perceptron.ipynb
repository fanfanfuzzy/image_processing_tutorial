{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7cf3d03",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Google Colab Setup / Google Colab セットアップ\n",
    "try:\n",
    "    import google.colab\n",
    "    IN_COLAB = True\n",
    "except ImportError:\n",
    "    IN_COLAB = False\n",
    "\n",
    "if IN_COLAB:\n",
    "    from google.colab import drive\n",
    "    drive.mount('/content/drive')\n",
    "    \n",
    "    import sys\n",
    "    from pathlib import Path\n",
    "    \n",
    "    proj_root = Path(\"/content/drive/MyDrive/image_processing_tutorial-main\")\n",
    "    if str(proj_root) not in sys.path:\n",
    "        sys.path.insert(0, str(proj_root))\n",
    "    \n",
    "    print(\"Google Colab environment detected and configured!\")\n",
    "    print(\"Google Colab環境が検出され、設定されました！\")\n",
    "else:\n",
    "    print(\"Local Jupyter environment detected\")\n",
    "    print(\"ローカルJupyter環境が検出されました\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "146313b2",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "This tutorial demonstrates nonlinear classification using multilayer perceptrons implemented with PyTorch. We'll compare linear and nonlinear models on a sinusoidal boundary classification problem.\n",
    "\n",
    "このチュートリアルでは、PyTorchで実装した多層パーセプトロンを使用した非線形分類を実演します。正弦波境界分類問題で線形モデルと非線形モデルを比較します。\n",
    "\n",
    "- Understand limitations of linear models / 線形モデルの限界を理解\n",
    "- Implement MLP using PyTorch / PyTorchを使用してMLPを実装\n",
    "- Compare linear vs nonlinear classification / 線形vs非線形分類の比較\n",
    "- Visualize decision boundaries / 決定境界の可視化\n",
    "- Analyze model performance / モデル性能の解析\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b81a70c",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "**Question:** How do we set up PyTorch for deep learning and create a challenging nonlinear classification problem?\n",
    "\n",
    "**質問:** 深層学習のためにPyTorchをセットアップし、挑戦的な非線形分類問題を作成するにはどうすればよいですか？\n",
    "\n",
    "**Answer:** We'll import PyTorch and related libraries, then generate data with a sinusoidal decision boundary that linear models cannot handle effectively.\n",
    "\n",
    "**回答:** PyTorchと関連ライブラリをインポートし、線形モデルでは効果的に処理できない正弦波決定境界を持つデータを生成します。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dddb3088",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "import seaborn as sns\n",
    "\n",
    "np.random.seed(42)\n",
    "torch.manual_seed(42)\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Using device: {device}\")\n",
    "print(f\"使用デバイス: {device}\")\n",
    "\n",
    "print(\"Libraries imported successfully / ライブラリのインポートが完了しました\")\n",
    "print(\"PyTorch version:\", torch.__version__)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44334485",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "N = 500  # Number of samples / サンプル数\n",
    "\n",
    "x = np.random.uniform(low=-1, high=1, size=(N, 2))\n",
    "y = np.zeros(N)\n",
    "\n",
    "y[x[:, 1] - np.sin(2*np.pi*x[:, 0]) > 0] = 1\n",
    "\n",
    "plt.figure(figsize=(10, 8))\n",
    "plt.plot(x[y==0, 0], x[y==0, 1], 'bo', alpha=0.6, label='Class 0', markersize=6)\n",
    "plt.plot(x[y==1, 0], x[y==1, 1], 'ro', alpha=0.6, label='Class 1', markersize=6)\n",
    "\n",
    "xx = np.linspace(-1, 1, 200)\n",
    "yy = np.sin(2*np.pi*xx)\n",
    "plt.plot(xx, yy, 'g-', linewidth=3, label='True Boundary')\n",
    "\n",
    "plt.xlim(-1, 1)\n",
    "plt.ylim(-1, 1)\n",
    "plt.xlabel('X1')\n",
    "plt.ylabel('X2')\n",
    "plt.title('Nonlinear Classification Problem: Sinusoidal Boundary')\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.show()\n",
    "\n",
    "print(f\"Generated {N} samples with sinusoidal decision boundary\")\n",
    "print(f\"正弦波決定境界を持つ{N}個のサンプルを生成しました\")\n",
    "print(f\"Class 0: {np.sum(y==0)} samples, Class 1: {np.sum(y==1)} samples\")\n",
    "print(f\"クラス0: {np.sum(y==0)}サンプル、クラス1: {np.sum(y==1)}サンプル\")\n",
    "\n",
    "X_tensor = torch.FloatTensor(x).to(device)\n",
    "y_tensor = torch.FloatTensor(y).to(device)\n",
    "\n",
    "print(\"Data converted to PyTorch tensors / データをPyTorchテンソルに変換しました\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4788c5f",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "**Question:** How do we create a linear baseline model using PyTorch to understand the limitations of linear classification?\n",
    "\n",
    "**質問:** 線形分類の限界を理解するために、PyTorchを使用して線形ベースラインモデルを作成するにはどうすればよいですか？\n",
    "\n",
    "**Answer:** We'll implement a simple linear model with one fully connected layer and sigmoid activation, then train it to see how it performs on the nonlinear problem.\n",
    "\n",
    "**回答:** 1つの全結合層とシグモイド活性化を持つシンプルな線形モデルを実装し、非線形問題でのパフォーマンスを確認するために訓練します。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8033a2ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class LinearModel(nn.Module):\n",
    "    def __init__(self, input_dim=2):\n",
    "        super(LinearModel, self).__init__()\n",
    "        self.linear = nn.Linear(input_dim, 1)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.sigmoid(self.linear(x))\n",
    "\n",
    "linear_model = LinearModel().to(device)\n",
    "linear_criterion = nn.BCELoss()\n",
    "linear_optimizer = optim.Adam(linear_model.parameters(), lr=0.01)\n",
    "\n",
    "print(\"Linear model architecture:\")\n",
    "print(\"線形モデルアーキテクチャ:\")\n",
    "print(linear_model)\n",
    "\n",
    "epochs = 1000\n",
    "batch_size = 100\n",
    "\n",
    "dataset = TensorDataset(X_tensor, y_tensor.unsqueeze(1))\n",
    "dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "print(f\"Training linear model for {epochs} epochs...\")\n",
    "print(f\"線形モデルを{epochs}エポック訓練中...\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7141e48a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "linear_losses = []\n",
    "linear_accuracies = []\n",
    "\n",
    "linear_model.train()\n",
    "for epoch in range(epochs):\n",
    "    epoch_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    \n",
    "    for batch_x, batch_y in dataloader:\n",
    "        linear_optimizer.zero_grad()\n",
    "        outputs = linear_model(batch_x)\n",
    "        loss = linear_criterion(outputs, batch_y)\n",
    "        loss.backward()\n",
    "        linear_optimizer.step()\n",
    "        \n",
    "        epoch_loss += loss.item()\n",
    "        predicted = (outputs > 0.5).float()\n",
    "        total += batch_y.size(0)\n",
    "        correct += (predicted == batch_y).sum().item()\n",
    "    \n",
    "    avg_loss = epoch_loss / len(dataloader)\n",
    "    accuracy = correct / total\n",
    "    linear_losses.append(avg_loss)\n",
    "    linear_accuracies.append(accuracy)\n",
    "    \n",
    "    if (epoch + 1) % 200 == 0:\n",
    "        print(f\"Epoch {epoch+1}: Loss = {avg_loss:.4f}, Accuracy = {accuracy:.4f}\")\n",
    "        print(f\"エポック {epoch+1}: 損失 = {avg_loss:.4f}, 精度 = {accuracy:.4f}\")\n",
    "\n",
    "print(\"Linear model training completed!\")\n",
    "print(\"線形モデルの訓練が完了しました！\")\n",
    "\n",
    "plt.figure(figsize=(12, 4))\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(linear_losses, 'b-', linewidth=2)\n",
    "plt.title('Linear Model: Loss Evolution')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(linear_accuracies, 'r-', linewidth=2)\n",
    "plt.title('Linear Model: Accuracy Evolution')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "final_linear_loss = linear_losses[-1]\n",
    "final_linear_accuracy = linear_accuracies[-1]\n",
    "print(f\"Linear model final loss: {final_linear_loss:.4f}\")\n",
    "print(f\"Linear model final accuracy: {final_linear_accuracy:.4f}\")\n",
    "print(f\"線形モデル最終損失: {final_linear_loss:.4f}\")\n",
    "print(f\"線形モデル最終精度: {final_linear_accuracy:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f01a3bb",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "**Question:** How do we implement a multilayer perceptron in PyTorch to handle nonlinear classification problems?\n",
    "\n",
    "**質問:** 非線形分類問題を処理するために、PyTorchで多層パーセプトロンを実装するにはどうすればよいですか？\n",
    "\n",
    "**Answer:** We'll create an MLP with hidden layers and ReLU activation functions, which can learn complex nonlinear decision boundaries.\n",
    "\n",
    "**回答:** 隠れ層とReLU活性化関数を持つMLPを作成し、複雑な非線形決定境界を学習できるようにします。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6da23157",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class MLPModel(nn.Module):\n",
    "    def __init__(self, input_dim=2, hidden_dim=5, output_dim=1):\n",
    "        super(MLPModel, self).__init__()\n",
    "        self.hidden = nn.Linear(input_dim, hidden_dim)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.output = nn.Linear(hidden_dim, output_dim)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.hidden(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.output(x)\n",
    "        return self.sigmoid(x)\n",
    "\n",
    "mlp_model = MLPModel().to(device)\n",
    "mlp_criterion = nn.BCELoss()\n",
    "mlp_optimizer = optim.Adam(mlp_model.parameters(), lr=0.01)\n",
    "\n",
    "print(\"MLP Model Architecture:\")\n",
    "print(\"MLPモデルアーキテクチャ:\")\n",
    "print(mlp_model)\n",
    "\n",
    "total_params = sum(p.numel() for p in mlp_model.parameters())\n",
    "trainable_params = sum(p.numel() for p in mlp_model.parameters() if p.requires_grad)\n",
    "\n",
    "print(f\"Total parameters: {total_params}\")\n",
    "print(f\"Trainable parameters: {trainable_params}\")\n",
    "print(f\"総パラメータ数: {total_params}\")\n",
    "print(f\"訓練可能パラメータ数: {trainable_params}\")\n",
    "\n",
    "print(\"MLP model built successfully!\")\n",
    "print(\"MLPモデルの構築が完了しました！\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99ff440e",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "**Question:** How do we train the MLP model and compare its performance with the linear baseline?\n",
    "\n",
    "**質問:** MLPモデルを訓練し、線形ベースラインとの性能を比較するにはどうすればよいですか？\n",
    "\n",
    "**Answer:** We'll train the MLP for more epochs and compare loss evolution, accuracy, and final performance metrics.\n",
    "\n",
    "**回答:** MLPをより多くのエポックで訓練し、損失の変化、精度、最終性能指標を比較します。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17906a19",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "mlp_epochs = 2000\n",
    "mlp_losses = []\n",
    "mlp_accuracies = []\n",
    "\n",
    "print(f\"Training MLP model for {mlp_epochs} epochs...\")\n",
    "print(f\"MLPモデルを{mlp_epochs}エポック訓練中...\")\n",
    "\n",
    "mlp_model.train()\n",
    "for epoch in range(mlp_epochs):\n",
    "    epoch_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    \n",
    "    for batch_x, batch_y in dataloader:\n",
    "        mlp_optimizer.zero_grad()\n",
    "        outputs = mlp_model(batch_x)\n",
    "        loss = mlp_criterion(outputs, batch_y)\n",
    "        loss.backward()\n",
    "        mlp_optimizer.step()\n",
    "        \n",
    "        epoch_loss += loss.item()\n",
    "        predicted = (outputs > 0.5).float()\n",
    "        total += batch_y.size(0)\n",
    "        correct += (predicted == batch_y).sum().item()\n",
    "    \n",
    "    avg_loss = epoch_loss / len(dataloader)\n",
    "    accuracy = correct / total\n",
    "    mlp_losses.append(avg_loss)\n",
    "    mlp_accuracies.append(accuracy)\n",
    "    \n",
    "    if (epoch + 1) % 400 == 0:\n",
    "        print(f\"Epoch {epoch+1}: Loss = {avg_loss:.4f}, Accuracy = {accuracy:.4f}\")\n",
    "        print(f\"エポック {epoch+1}: 損失 = {avg_loss:.4f}, 精度 = {accuracy:.4f}\")\n",
    "\n",
    "print(\"MLP model training completed!\")\n",
    "print(\"MLPモデルの訓練が完了しました！\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7a875ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "plt.figure(figsize=(15, 5))\n",
    "\n",
    "plt.subplot(1, 3, 1)\n",
    "plt.plot(linear_losses, 'b-', linewidth=2, label='Linear Model')\n",
    "plt.plot(mlp_losses, 'r-', linewidth=2, label='MLP Model')\n",
    "plt.title('Loss Evolution Comparison')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.yscale('log')  # Log scale for better visualization / より良い可視化のための対数スケール\n",
    "\n",
    "plt.subplot(1, 3, 2)\n",
    "plt.plot(linear_accuracies, 'b-', linewidth=2, label='Linear Model')\n",
    "plt.plot(mlp_accuracies, 'r-', linewidth=2, label='MLP Model')\n",
    "plt.title('Accuracy Evolution Comparison')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "models = ['Linear', 'MLP']\n",
    "final_losses = [linear_losses[-1], mlp_losses[-1]]\n",
    "final_accuracies = [linear_accuracies[-1], mlp_accuracies[-1]]\n",
    "\n",
    "plt.subplot(1, 3, 3)\n",
    "x_pos = np.arange(len(models))\n",
    "plt.bar(x_pos, final_accuracies, alpha=0.7, color=['blue', 'red'])\n",
    "plt.xlabel('Model Type')\n",
    "plt.ylabel('Final Accuracy')\n",
    "plt.title('Final Accuracy Comparison')\n",
    "plt.xticks(x_pos, models)\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "for i, acc in enumerate(final_accuracies):\n",
    "    plt.text(i, acc + 0.01, f'{acc:.3f}', ha='center', va='bottom')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"MODEL PERFORMANCE COMPARISON / モデル性能比較\")\n",
    "print(\"=\"*50)\n",
    "print(f\"Linear Model - Loss: {final_losses[0]:.4f}, Accuracy: {final_accuracies[0]:.4f}\")\n",
    "print(f\"MLP Model    - Loss: {final_losses[1]:.4f}, Accuracy: {final_accuracies[1]:.4f}\")\n",
    "print(f\"線形モデル - 損失: {final_losses[0]:.4f}, 精度: {final_accuracies[0]:.4f}\")\n",
    "print(f\"MLPモデル  - 損失: {final_losses[1]:.4f}, 精度: {final_accuracies[1]:.4f}\")\n",
    "print(\"=\"*50)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3c703ed",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "**Question:** How can we visualize and compare the decision boundaries learned by linear and MLP models?\n",
    "\n",
    "**質問:** 線形モデルとMLPモデルが学習した決定境界をどのように可視化し比較できますか？\n",
    "\n",
    "**Answer:** We'll create prediction grids and visualize the decision boundaries, comparing them with the true sinusoidal boundary.\n",
    "\n",
    "**回答:** 予測グリッドを作成し決定境界を可視化し、真の正弦波境界と比較します。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9b7ec6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def create_meshgrid(resolution=128):\n",
    "    \"\"\"Create meshgrid for visualization / 可視化用メッシュグリッド作成\"\"\"\n",
    "    xx = np.linspace(-1, 1, resolution)\n",
    "    yy = np.linspace(-1, 1, resolution)\n",
    "    XX, YY = np.meshgrid(xx, yy)\n",
    "    grid_points = np.hstack((XX.reshape(-1, 1), YY.reshape(-1, 1)))\n",
    "    return XX, YY, grid_points\n",
    "\n",
    "XX, YY, grid_points = create_meshgrid(128)\n",
    "grid_tensor = torch.FloatTensor(grid_points).to(device)\n",
    "\n",
    "linear_model.eval()\n",
    "mlp_model.eval()\n",
    "\n",
    "with torch.no_grad():\n",
    "    linear_predictions = linear_model(grid_tensor).cpu().numpy().reshape(128, 128)\n",
    "    mlp_predictions = mlp_model(grid_tensor).cpu().numpy().reshape(128, 128)\n",
    "\n",
    "print(\"Decision boundary predictions generated\")\n",
    "print(\"決定境界予測が生成されました\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36e3a448",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "fig, axes = plt.subplots(2, 2, figsize=(15, 12))\n",
    "\n",
    "axes[0, 0].contourf(XX, YY, linear_predictions, levels=50, alpha=0.6, cmap='RdYlBu')\n",
    "axes[0, 0].plot(x[y==0, 0], x[y==0, 1], 'bo', alpha=0.6, markersize=3)\n",
    "axes[0, 0].plot(x[y==1, 0], x[y==1, 1], 'ro', alpha=0.6, markersize=3)\n",
    "axes[0, 0].set_title('Linear Model Decision Boundary')\n",
    "axes[0, 0].set_xlabel('X1')\n",
    "axes[0, 0].set_ylabel('X2')\n",
    "axes[0, 0].grid(True, alpha=0.3)\n",
    "\n",
    "im = axes[0, 1].contourf(XX, YY, mlp_predictions, levels=50, alpha=0.6, cmap='RdYlBu')\n",
    "axes[0, 1].plot(x[y==0, 0], x[y==0, 1], 'bo', alpha=0.6, markersize=3)\n",
    "axes[0, 1].plot(x[y==1, 0], x[y==1, 1], 'ro', alpha=0.6, markersize=3)\n",
    "axes[0, 1].set_title('MLP Model Decision Boundary')\n",
    "axes[0, 1].set_xlabel('X1')\n",
    "axes[0, 1].set_ylabel('X2')\n",
    "axes[0, 1].grid(True, alpha=0.3)\n",
    "\n",
    "plt.colorbar(im, ax=axes[0, 1], label='Prediction Probability')\n",
    "\n",
    "xx_true = np.linspace(-1, 1, 200)\n",
    "yy_true = np.sin(2*np.pi*xx_true)\n",
    "\n",
    "axes[1, 0].plot(x[y==0, 0], x[y==0, 1], 'bo', alpha=0.4, markersize=4, label='Class 0')\n",
    "axes[1, 0].plot(x[y==1, 0], x[y==1, 1], 'ro', alpha=0.4, markersize=4, label='Class 1')\n",
    "axes[1, 0].plot(xx_true, yy_true, 'g-', linewidth=3, label='True Boundary')\n",
    "axes[1, 0].contour(XX, YY, linear_predictions, levels=[0.5], colors='blue', linewidths=2, linestyles='--', label='Linear Boundary')\n",
    "axes[1, 0].set_title('Linear Model vs True Boundary')\n",
    "axes[1, 0].set_xlabel('X1')\n",
    "axes[1, 0].set_ylabel('X2')\n",
    "axes[1, 0].legend()\n",
    "axes[1, 0].grid(True, alpha=0.3)\n",
    "\n",
    "axes[1, 1].plot(x[y==0, 0], x[y==0, 1], 'bo', alpha=0.4, markersize=4, label='Class 0')\n",
    "axes[1, 1].plot(x[y==1, 0], x[y==1, 1], 'ro', alpha=0.4, markersize=4, label='Class 1')\n",
    "axes[1, 1].plot(xx_true, yy_true, 'g-', linewidth=3, label='True Boundary')\n",
    "axes[1, 1].contour(XX, YY, mlp_predictions, levels=[0.5], colors='red', linewidths=2, linestyles='--', label='MLP Boundary')\n",
    "axes[1, 1].set_title('MLP Model vs True Boundary')\n",
    "axes[1, 1].set_xlabel('X1')\n",
    "axes[1, 1].set_ylabel('X2')\n",
    "axes[1, 1].legend()\n",
    "axes[1, 1].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5fa95ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "linear_model.eval()\n",
    "mlp_model.eval()\n",
    "\n",
    "with torch.no_grad():\n",
    "    linear_train_pred = (linear_model(X_tensor) > 0.5).float().cpu().numpy().flatten()\n",
    "    mlp_train_pred = (mlp_model(X_tensor) > 0.5).float().cpu().numpy().flatten()\n",
    "\n",
    "linear_errors = np.sum(linear_train_pred != y)\n",
    "mlp_errors = np.sum(mlp_train_pred != y)\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"CLASSIFICATION ERROR ANALYSIS / 分類誤差解析\")\n",
    "print(\"=\"*60)\n",
    "print(f\"Linear Model - Training Errors: {linear_errors}/{len(y)} ({linear_errors/len(y)*100:.1f}%)\")\n",
    "print(f\"MLP Model    - Training Errors: {mlp_errors}/{len(y)} ({mlp_errors/len(y)*100:.1f}%)\")\n",
    "print(f\"線形モデル - 訓練誤差: {linear_errors}/{len(y)} ({linear_errors/len(y)*100:.1f}%)\")\n",
    "print(f\"MLPモデル  - 訓練誤差: {mlp_errors}/{len(y)} ({mlp_errors/len(y)*100:.1f}%)\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "print(\"\\nTutorial completed! / チュートリアル完了！\")\n",
    "print(\"Key insights / 主要な洞察:\")\n",
    "print(\"- Linear models struggle with nonlinear boundaries / 線形モデルは非線形境界に苦戦\")\n",
    "print(\"- MLPs can learn complex decision boundaries / MLPは複雑な決定境界を学習可能\")\n",
    "print(\"- PyTorch provides flexible neural network implementation / PyTorchは柔軟なニューラルネットワーク実装を提供\")\n"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
