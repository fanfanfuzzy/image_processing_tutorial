{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ad430d54",
   "metadata": {},
   "source": [
    "# Perceptron Classification Tutorial / パーセプトロン分類チュートリアル\n",
    "\n",
    "\n",
    "In this tutorial, you will learn:\n",
    "このチュートリアルでは、以下を学習します：\n",
    "\n",
    "- **Binary classification with perceptron** / パーセプトロンによる二値分類\n",
    "- **Error correction learning algorithm** / 誤り訂正学習アルゴリズム  \n",
    "- **Weight update visualization** / 重み更新の可視化\n",
    "- **Cost function analysis** / コスト関数解析\n",
    "\n",
    "\n",
    "The perceptron is one of the simplest neural network models for binary classification. It uses an error correction learning algorithm to find a linear decision boundary that separates two classes.\n",
    "\n",
    "パーセプトロンは二値分類のための最もシンプルなニューラルネットワークモデルの一つです。誤り訂正学習アルゴリズムを使用して、2つのクラスを分離する線形決定境界を見つけます。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c48421e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required libraries / 必要なライブラリをインポート\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import matplotlib.animation as animation\n",
    "\n",
    "np.random.seed(12345)\n",
    "\n",
    "sns.set()\n",
    "sns.set_context('talk')\n",
    "plt.rcParams['axes.grid'] = False\n",
    "plt.rcParams['font.size'] = 20\n",
    "plt.rcParams['xtick.labelsize'] = 14\n",
    "plt.rcParams['ytick.labelsize'] = 14\n",
    "plt.rcParams['image.cmap'] = 'plasma'\n",
    "\n",
    "print(\"Libraries imported successfully / ライブラリのインポートが完了しました\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "247c723f",
   "metadata": {},
   "source": [
    "## Q1: Generate 2D Gaussian Classification Data / 2次元ガウス分類データの生成\n",
    "\n",
    "Generate two classes of 2D data points using multivariate normal distributions for binary classification.\n",
    "\n",
    "二値分類のために多変量正規分布を使用して2つのクラスの2次元データポイントを生成します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a83850a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate 2D Gaussian data for binary classification / 二値分類用2次元ガウスデータ生成\n",
    "mu1 = np.array([1, 3])  # Class 1 center / クラス1の中心\n",
    "mu2 = np.array([3, 1])  # Class 2 center / クラス2の中心\n",
    "cov = 2 * np.array([[1.0, 0.2], [0.2, 0.3]])  # Shared covariance matrix / 共通共分散行列\n",
    "\n",
    "N1 = 50  # Number of samples for class 1 / クラス1のサンプル数\n",
    "N2 = 30  # Number of samples for class 2 / クラス2のサンプル数\n",
    "\n",
    "x1 = np.random.multivariate_normal(mu1, cov, N1)\n",
    "x2 = np.random.multivariate_normal(mu2, cov, N2)\n",
    "x = np.vstack((x1, x2))\n",
    "\n",
    "y1 = np.ones(N1)\n",
    "y2 = -np.ones(N2)\n",
    "y = np.hstack((y1, y2))\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.plot(x[y==1, 0], x[y==1, 1], 'ro', alpha=0.7, label='Class +1', markersize=8)\n",
    "plt.plot(x[y==-1, 0], x[y==-1, 1], 'bo', alpha=0.7, label='Class -1', markersize=8)\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.xlabel('X1')\n",
    "plt.ylabel('X2')\n",
    "plt.title('2D Binary Classification Data')\n",
    "plt.legend()\n",
    "plt.axis('equal')\n",
    "plt.show()\n",
    "\n",
    "print(f\"Generated {N1} samples for class +1 and {N2} samples for class -1\")\n",
    "print(f\"クラス+1に{N1}個、クラス-1に{N2}個のサンプルを生成しました\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35ba1c4b",
   "metadata": {},
   "source": [
    "## Q2: Implement Perceptron Prediction Function / パーセプトロン予測関数の実装\n",
    "\n",
    "Implement the core functions for perceptron prediction and weight computation.\n",
    "\n",
    "パーセプトロンの予測と重み計算のためのコア関数を実装します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9974d1af",
   "metadata": {},
   "outputs": [],
   "source": [
    "def weight_sum(w, x):\n",
    "    \"\"\"\n",
    "    Compute weighted sum for perceptron\n",
    "    パーセプトロンの重み付き和を計算\n",
    "    \n",
    "    Parameters:\n",
    "    w: weight vector (D+1 dimensions including bias) / 重みベクトル（バイアス含むD+1次元）\n",
    "    x: input data matrix (N, D) / 入力データ行列 (N, D)\n",
    "    \n",
    "    Returns:\n",
    "    Weighted sum for each input / 各入力の重み付き和\n",
    "    \"\"\"\n",
    "    N = x.shape[0]\n",
    "    x_with_bias = np.hstack((np.ones((N, 1)), x))\n",
    "    return x_with_bias @ w\n",
    "\n",
    "def predict(x, w):\n",
    "    \"\"\"\n",
    "    Perceptron prediction function (returns ±1)\n",
    "    パーセプトロン予測関数（±1を返す）\n",
    "    \n",
    "    Parameters:\n",
    "    x: input data / 入力データ\n",
    "    w: weight vector / 重みベクトル\n",
    "    \n",
    "    Returns:\n",
    "    Predicted class labels (±1) / 予測クラスラベル（±1）\n",
    "    \"\"\"\n",
    "    return np.sign(weight_sum(w, x))\n",
    "\n",
    "def draw_decision_boundary(x, y, w, xlim=(-3, 12), ylim=(-6, 6)):\n",
    "    \"\"\"\n",
    "    Draw decision boundary line\n",
    "    決定境界線を描画\n",
    "    \n",
    "    Parameters:\n",
    "    x, y: data points and labels / データポイントとラベル\n",
    "    w: weight vector / 重みベクトル\n",
    "    xlim, ylim: plot limits / プロット範囲\n",
    "    \"\"\"\n",
    "    xx1 = np.linspace(xlim[0], xlim[1], 100)\n",
    "    xx2 = -(w[0] + w[1] * xx1) / w[2]\n",
    "    \n",
    "    plt.plot(xx1, xx2, 'g-', linewidth=3, label='Decision Boundary')\n",
    "    return plt.gca().lines[-1]\n",
    "\n",
    "print(\"Perceptron functions implemented successfully\")\n",
    "print(\"パーセプトロン関数の実装が完了しました\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af96ed09",
   "metadata": {},
   "source": [
    "## Q3: Implement Error Correction Learning / 誤り訂正学習の実装\n",
    "\n",
    "Implement the error correction learning algorithm to update perceptron weights.\n",
    "\n",
    "パーセプトロンの重みを更新する誤り訂正学習アルゴリズムを実装します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d843687",
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_weights(w, x, t, eta=0.0025):\n",
    "    \"\"\"\n",
    "    Update perceptron weights using error correction learning\n",
    "    誤り訂正学習を使用してパーセプトロンの重みを更新\n",
    "    \n",
    "    Parameters:\n",
    "    w: current weight vector / 現在の重みベクトル\n",
    "    x: input data / 入力データ\n",
    "    t: target labels / 目標ラベル\n",
    "    eta: learning rate / 学習率\n",
    "    \n",
    "    Returns:\n",
    "    Updated weight vector / 更新された重みベクトル\n",
    "    \"\"\"\n",
    "    ws = weight_sum(w, x)\n",
    "    \n",
    "    N = x.shape[0]\n",
    "    x_with_bias = np.hstack((np.ones((N, 1)), x))\n",
    "    \n",
    "    misclassified = t * ws < 0\n",
    "    \n",
    "    if np.any(misclassified):\n",
    "        delta = eta * np.sum(t[misclassified, np.newaxis] * x_with_bias[misclassified, :], axis=0)\n",
    "        w = w + delta\n",
    "    \n",
    "    return w\n",
    "\n",
    "def compute_cost(w, x, t):\n",
    "    \"\"\"\n",
    "    Compute perceptron cost function\n",
    "    パーセプトロンのコスト関数を計算\n",
    "    \n",
    "    Parameters:\n",
    "    w: weight vector / 重みベクトル\n",
    "    x: input data / 入力データ\n",
    "    t: target labels / 目標ラベル\n",
    "    \n",
    "    Returns:\n",
    "    Cost function value / コスト関数値\n",
    "    \"\"\"\n",
    "    ws = weight_sum(w, x)\n",
    "    misclassified = t * ws < 0\n",
    "    \n",
    "    if np.any(misclassified):\n",
    "        return -np.sum(ws[misclassified] * t[misclassified])\n",
    "    else:\n",
    "        return 0.0\n",
    "\n",
    "print(\"Error correction learning functions implemented\")\n",
    "print(\"誤り訂正学習関数の実装が完了しました\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94bbe10f",
   "metadata": {},
   "source": [
    "## Q4: Visualize Learning Process / 学習過程の可視化\n",
    "\n",
    "Train the perceptron and visualize how the decision boundary evolves during learning.\n",
    "\n",
    "パーセプトロンを訓練し、学習中に決定境界がどのように変化するかを可視化します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e9aeafe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize random weights / ランダムな重みで初期化\n",
    "w = np.random.uniform(low=-1, high=1, size=3)\n",
    "print(f\"Initial weights: {w}\")\n",
    "print(f\"初期重み: {w}\")\n",
    "\n",
    "xlim = [-3, 12]\n",
    "ylim = [-6, 6]\n",
    "\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 6))\n",
    "\n",
    "ax1.plot(x[y==1, 0], x[y==1, 1], 'ro', alpha=0.7, label='Class +1', markersize=8)\n",
    "ax1.plot(x[y==-1, 0], x[y==-1, 1], 'bo', alpha=0.7, label='Class -1', markersize=8)\n",
    "ax1.set_xlim(xlim)\n",
    "ax1.set_ylim(ylim)\n",
    "ax1.grid(True, alpha=0.3)\n",
    "ax1.set_xlabel('X1')\n",
    "ax1.set_ylabel('X2')\n",
    "ax1.set_title('Perceptron Learning Result')\n",
    "ax1.legend()\n",
    "\n",
    "costs = []\n",
    "weights_history = []\n",
    "\n",
    "initial_cost = compute_cost(w, x, y)\n",
    "costs.append(initial_cost)\n",
    "weights_history.append(w.copy())\n",
    "\n",
    "print(f\"Initial cost: {initial_cost:.4f}\")\n",
    "print(f\"初期コスト: {initial_cost:.4f}\")\n",
    "\n",
    "max_epochs = 200\n",
    "for epoch in range(max_epochs):\n",
    "    w_old = w.copy()\n",
    "    w = update_weights(w, x, y, eta=0.0025)\n",
    "    cost = compute_cost(w, x, y)\n",
    "    costs.append(cost)\n",
    "    weights_history.append(w.copy())\n",
    "    \n",
    "    if (epoch + 1) % 50 == 0:\n",
    "        print(f\"Epoch {epoch+1}: Cost = {cost:.4f}\")\n",
    "        print(f\"エポック {epoch+1}: コスト = {cost:.4f}\")\n",
    "    \n",
    "    if cost == 0.0:\n",
    "        print(f\"Converged at epoch {epoch+1}\")\n",
    "        print(f\"エポック {epoch+1} で収束しました\")\n",
    "        break\n",
    "\n",
    "draw_decision_boundary(x, y, w, xlim, ylim)\n",
    "\n",
    "print(f\"Final weights: {w}\")\n",
    "print(f\"最終重み: {w}\")\n",
    "print(f\"Final cost: {costs[-1]:.4f}\")\n",
    "print(f\"最終コスト: {costs[-1]:.4f}\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d31f43f",
   "metadata": {},
   "source": [
    "## Q5: Analyze Cost Function Evolution / コスト関数の変化解析\n",
    "\n",
    "Analyze how the cost function decreases during the learning process.\n",
    "\n",
    "学習過程でコスト関数がどのように減少するかを分析します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41dbee8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot cost function evolution / コスト関数の変化をプロット\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.semilogy(costs, 'b-', linewidth=2, marker='o', markersize=4)\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Cost Function Value')\n",
    "plt.title('Perceptron Learning: Cost Function Evolution')\n",
    "plt.show()\n",
    "\n",
    "predictions = predict(x, w)\n",
    "accuracy = np.mean(predictions == y)\n",
    "print(f\"Final classification accuracy: {accuracy:.2%}\")\n",
    "print(f\"最終分類精度: {accuracy:.2%}\")\n",
    "\n",
    "weights_array = np.array(weights_history)\n",
    "plt.figure(figsize=(12, 4))\n",
    "\n",
    "for i in range(3):\n",
    "    plt.subplot(1, 3, i+1)\n",
    "    plt.plot(weights_array[:, i], 'g-', linewidth=2)\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel(f'Weight w{i}')\n",
    "    plt.title(f'Weight w{i} Evolution')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nPerceptron learning analysis completed!\")\n",
    "print(\"パーセプトロン学習解析が完了しました！\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37b6193d",
   "metadata": {},
   "source": [
    "## Summary / まとめ\n",
    "\n",
    "In this tutorial, you learned:\n",
    "このチュートリアルでは以下を学習しました：\n",
    "\n",
    "1. **Data Generation**: How to create 2D Gaussian data for binary classification\n",
    "   **データ生成**: 二値分類のための2次元ガウスデータの作成方法\n",
    "\n",
    "2. **Perceptron Implementation**: Core functions for prediction and weight computation\n",
    "   **パーセプトロン実装**: 予測と重み計算のためのコア関数\n",
    "\n",
    "3. **Error Correction Learning**: Algorithm to update weights based on misclassified samples\n",
    "   **誤り訂正学習**: 誤分類されたサンプルに基づく重み更新アルゴリズム\n",
    "\n",
    "4. **Visualization**: How to visualize the learning process and decision boundary evolution\n",
    "   **可視化**: 学習過程と決定境界の変化の可視化方法\n",
    "\n",
    "5. **Analysis**: Cost function evolution and convergence behavior\n",
    "   **解析**: コスト関数の変化と収束挙動\n",
    "\n",
    "The perceptron is a fundamental building block for more complex neural networks. Understanding its learning mechanism provides the foundation for advanced machine learning techniques.\n",
    "\n",
    "パーセプトロンは、より複雑なニューラルネットワークの基本的な構成要素です。その学習メカニズムを理解することで、高度な機械学習技術の基礎が得られます。"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
