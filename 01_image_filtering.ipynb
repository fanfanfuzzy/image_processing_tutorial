{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9627719",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Google Colab Setup / Google Colab セットアップ\n",
    "try:\n",
    "    import google.colab\n",
    "    IN_COLAB = True\n",
    "except ImportError:\n",
    "    IN_COLAB = False\n",
    "\n",
    "if IN_COLAB:\n",
    "    from google.colab import drive\n",
    "    drive.mount('/content/drive')\n",
    "    \n",
    "    import sys\n",
    "    from pathlib import Path\n",
    "    \n",
    "    proj_root = Path(\"/content/drive/MyDrive/image_processing_tutorial-main\")\n",
    "    if str(proj_root) not in sys.path:\n",
    "        sys.path.insert(0, str(proj_root))\n",
    "    \n",
    "    print(\"Google Colab environment detected and configured!\")\n",
    "    print(\"Google Colab環境が検出され、設定されました！\")\n",
    "else:\n",
    "    print(\"Local Jupyter environment detected\")\n",
    "    print(\"ローカルJupyter環境が検出されました\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "223fd20b",
   "metadata": {},
   "source": [
    "# Image Filtering Tutorial / 画像フィルタリングチュートリアル\n",
    "\n",
    "This notebook demonstrates fundamental image processing techniques including smoothing filters, edge detection, and feature detection.\n",
    "\n",
    "このノートブックでは、平滑化フィルタ、エッジ検出、特徴検出を含む基本的な画像処理技術を実演します。\n",
    "\n",
    "1. Lena Image Download / レナ画像のダウンロード\n",
    "2. Smoothing Filters / 平滑化フィルタ\n",
    "3. Edge Detection with Sobel Filters / ソーベルフィルタによるエッジ検出\n",
    "4. Harris Corner Detection / ハリスコーナー検出\n",
    "5. SIFT Feature Detection / SIFT特徴点検出"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07138f9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required libraries / 必要なライブラリをインポート\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "import requests\n",
    "from skimage import filters, feature, io\n",
    "from scipy import ndimage\n",
    "import os\n",
    "\n",
    "plt.rcParams['figure.figsize'] = (12, 8)\n",
    "plt.rcParams['font.size'] = 12"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6250e07f",
   "metadata": {},
   "source": [
    "## 1. Lena Image Download / レナ画像のダウンロード\n",
    "\n",
    "We'll download the famous Lena image, which is commonly used in image processing tutorials.\n",
    "\n",
    "画像処理チュートリアルでよく使用される有名なレナ画像をダウンロードします。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be77ccb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_lena_image():\n",
    "    \"\"\"\n",
    "    Download Lena image from multiple reliable sources with fallback\n",
    "    複数の信頼できるソースからレナ画像をダウンロード（フォールバック付き）\n",
    "    \"\"\"\n",
    "    # Multiple URLs in order of preference / 優先順位順の複数URL\n",
    "    urls = [\n",
    "        \"https://raw.githubusercontent.com/opencv/opencv/master/samples/data/lena.jpg\",\n",
    "        \"https://upload.wikimedia.org/wikipedia/en/7/7d/Lenna_%28test_image%29.png\",\n",
    "    ]\n",
    "    \n",
    "    # Headers to avoid bot detection / ボット検出を回避するためのヘッダー\n",
    "    headers = {\n",
    "        'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36'\n",
    "    }\n",
    "    \n",
    "    for i, url in enumerate(urls):\n",
    "        try:\n",
    "            print(f\"Trying source {i+1}/{len(urls)}: {url.split('/')[-1]}\")\n",
    "            print(f\"ソース {i+1}/{len(urls)} を試行中: {url.split('/')[-1]}\")\n",
    "            \n",
    "            response = requests.get(url, headers=headers, timeout=30)\n",
    "            response.raise_for_status()\n",
    "            \n",
    "            # Determine file extension from URL / URLからファイル拡張子を決定\n",
    "            file_ext = 'jpg' if 'jpg' in url.lower() else 'png'\n",
    "            filename = f'lena.{file_ext}'\n",
    "            \n",
    "            with open(filename, 'wb') as f:\n",
    "                f.write(response.content)\n",
    "            \n",
    "            # Load and convert image / 画像を読み込み変換\n",
    "            img = cv2.imread(filename)\n",
    "            if img is None:\n",
    "                raise ValueError(f\"Failed to load image from {filename}\")\n",
    "            \n",
    "            img_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "            \n",
    "            print(f\"✓ Lena image downloaded successfully from source {i+1}!\")\n",
    "            print(f\"✓ ソース {i+1} からレナ画像のダウンロードが完了しました！\")\n",
    "            print(f\"Image shape: {img_rgb.shape}\")\n",
    "            print(f\"Source: {url}\")\n",
    "            \n",
    "            return img_rgb\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"❌ Source {i+1} failed: {e}\")\n",
    "            print(f\"❌ ソース {i+1} が失敗: {e}\")\n",
    "            if i < len(urls) - 1:\n",
    "                print(\"Trying next source... / 次のソースを試行中...\")\n",
    "            continue\n",
    "    \n",
    "    # If all sources fail, create synthetic image / 全ソースが失敗した場合、合成画像を作成\n",
    "    print(\"All download sources failed. Creating synthetic test image.\")\n",
    "    print(\"全ダウンロードソースが失敗しました。合成テスト画像を作成中。\")\n",
    "    \n",
    "    # Create a more realistic synthetic image instead of random noise\n",
    "    # ランダムノイズの代わりにより現実的な合成画像を作成\n",
    "    img = np.zeros((512, 512, 3), dtype=np.uint8)\n",
    "    \n",
    "    # Add some structure to make it useful for edge detection\n",
    "    # エッジ検出に有用な構造を追加\n",
    "    for i in range(0, 512, 64):\n",
    "        img[i:i+32, :] = [128, 128, 128]  # Horizontal stripes\n",
    "        img[:, i:i+32] = [64, 64, 64]    # Vertical stripes\n",
    "    \n",
    "    # Add a central circle for feature detection\n",
    "    # 特徴検出用の中央円を追加\n",
    "    center = (256, 256)\n",
    "    cv2.circle(img, center, 100, (255, 255, 255), -1)\n",
    "    cv2.circle(img, center, 80, (0, 0, 0), -1)\n",
    "    cv2.circle(img, center, 60, (200, 200, 200), -1)\n",
    "    \n",
    "    print(\"Synthetic test image created with structured patterns.\")\n",
    "    print(\"構造化パターンを持つ合成テスト画像を作成しました。\")\n",
    "    \n",
    "    return img\n",
    "lena_img = download_lena_image()\n",
    "lena_gray = cv2.cvtColor(lena_img, cv2.COLOR_RGB2GRAY)\n",
    "\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.imshow(lena_img)\n",
    "plt.title('Original Lena Image (Color)')\n",
    "plt.axis('off')\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.imshow(lena_gray, cmap='gray')\n",
    "plt.title('Grayscale Lena Image')\n",
    "plt.axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "150c1b47",
   "metadata": {},
   "source": [
    "## 2. Smoothing Filters / 平滑化フィルタ\n",
    "\n",
    "Smoothing filters are used to reduce noise and blur images. We'll demonstrate Gaussian and median filters.\n",
    "\n",
    "平滑化フィルタはノイズを減らし、画像をぼかすために使用されます。ガウシアンフィルタとメディアンフィルタを実演します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07f672ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply different smoothing filters\n",
    "gaussian_3 = cv2.GaussianBlur(lena_gray, (3, 3), 0)\n",
    "gaussian_9 = cv2.GaussianBlur(lena_gray, (9, 9), 0)\n",
    "gaussian_15 = cv2.GaussianBlur(lena_gray, (15, 15), 0)\n",
    "median_5 = cv2.medianBlur(lena_gray, 5)\n",
    "median_9 = cv2.medianBlur(lena_gray, 9)\n",
    "\n",
    "plt.figure(figsize=(15, 10))\n",
    "\n",
    "plt.subplot(2, 3, 1)\n",
    "plt.imshow(lena_gray, cmap='gray')\n",
    "plt.title('Original Image')\n",
    "plt.axis('off')\n",
    "\n",
    "plt.subplot(2, 3, 2)\n",
    "plt.imshow(gaussian_3, cmap='gray')\n",
    "plt.title('Gaussian Blur (3x3)')\n",
    "plt.axis('off')\n",
    "\n",
    "plt.subplot(2, 3, 3)\n",
    "plt.imshow(gaussian_9, cmap='gray')\n",
    "plt.title('Gaussian Blur (9x9)')\n",
    "plt.axis('off')\n",
    "\n",
    "plt.subplot(2, 3, 4)\n",
    "plt.imshow(gaussian_15, cmap='gray')\n",
    "plt.title('Gaussian Blur (15x15)')\n",
    "plt.axis('off')\n",
    "\n",
    "plt.subplot(2, 3, 5)\n",
    "plt.imshow(median_5, cmap='gray')\n",
    "plt.title('Median Filter (5x5)')\n",
    "plt.axis('off')\n",
    "\n",
    "plt.subplot(2, 3, 6)\n",
    "plt.imshow(median_9, cmap='gray')\n",
    "plt.title('Median Filter (9x9)')\n",
    "plt.axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2cd3ad6",
   "metadata": {},
   "source": [
    "## 3. Edge Detection with Sobel Filters / ソーベルフィルタによるエッジ検出\n",
    "\n",
    "Sobel filters detect edges by computing gradients in horizontal and vertical directions.\n",
    "\n",
    "ソーベルフィルタは水平および垂直方向の勾配を計算してエッジを検出します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eadb649c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply Sobel filters\n",
    "sobel_x = cv2.Sobel(lena_gray, cv2.CV_64F, 1, 0, ksize=3)\n",
    "sobel_y = cv2.Sobel(lena_gray, cv2.CV_64F, 0, 1, ksize=3)\n",
    "\n",
    "sobel_magnitude = np.sqrt(sobel_x**2 + sobel_y**2)\n",
    "sobel_direction = np.arctan2(sobel_y, sobel_x)\n",
    "\n",
    "kernel_diag1 = np.array([[-1, 0, 1], [-2, 0, 2], [-1, 0, 1]], dtype=np.float32)\n",
    "kernel_diag2 = np.array([[1, 2, 1], [0, 0, 0], [-1, -2, -1]], dtype=np.float32)\n",
    "\n",
    "sobel_diag1 = cv2.filter2D(lena_gray.astype(np.float32), -1, kernel_diag1)\n",
    "sobel_diag2 = cv2.filter2D(lena_gray.astype(np.float32), -1, kernel_diag2)\n",
    "\n",
    "plt.figure(figsize=(15, 10))\n",
    "\n",
    "plt.subplot(2, 3, 1)\n",
    "plt.imshow(lena_gray, cmap='gray')\n",
    "plt.title('Original Image')\n",
    "plt.axis('off')\n",
    "\n",
    "plt.subplot(2, 3, 2)\n",
    "plt.imshow(np.abs(sobel_x), cmap='gray')\n",
    "plt.title('Sobel X (Vertical Edges)')\n",
    "plt.axis('off')\n",
    "\n",
    "plt.subplot(2, 3, 3)\n",
    "plt.imshow(np.abs(sobel_y), cmap='gray')\n",
    "plt.title('Sobel Y (Horizontal Edges)')\n",
    "plt.axis('off')\n",
    "\n",
    "plt.subplot(2, 3, 4)\n",
    "plt.imshow(sobel_magnitude, cmap='gray')\n",
    "plt.title('Sobel Magnitude')\n",
    "plt.axis('off')\n",
    "\n",
    "plt.subplot(2, 3, 5)\n",
    "plt.imshow(np.abs(sobel_diag1), cmap='gray')\n",
    "plt.title('Diagonal Sobel 1')\n",
    "plt.axis('off')\n",
    "\n",
    "plt.subplot(2, 3, 6)\n",
    "plt.imshow(np.abs(sobel_diag2), cmap='gray')\n",
    "plt.title('Diagonal Sobel 2')\n",
    "plt.axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2aeb9678",
   "metadata": {},
   "source": [
    "## 4. SIFT Feature Detection / SIFT特徴点検出\n",
    "\n",
    "SIFT (Scale-Invariant Feature Transform) detects distinctive keypoints that are invariant to scale and rotation.\n",
    "\n",
    "SIFT（スケール不変特徴変換）は、スケールと回転に不変な特徴的なキーポイントを検出します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d201f37",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create SIFT detector\n",
    "sift = cv2.SIFT_create()\n",
    "\n",
    "keypoints, descriptors = sift.detectAndCompute(lena_gray, None)\n",
    "\n",
    "img_with_keypoints = cv2.drawKeypoints(lena_img, keypoints, None, \n",
    "                                      flags=cv2.DRAW_MATCHES_FLAGS_DRAW_RICH_KEYPOINTS)\n",
    "\n",
    "print(f\"Number of SIFT keypoints detected: {len(keypoints)}\")\n",
    "print(f\"Descriptor shape: {descriptors.shape if descriptors is not None else 'None'}\")\n",
    "\n",
    "plt.figure(figsize=(15, 5))\n",
    "\n",
    "plt.subplot(1, 3, 1)\n",
    "plt.imshow(lena_img)\n",
    "plt.title('Original Image')\n",
    "plt.axis('off')\n",
    "\n",
    "plt.subplot(1, 3, 2)\n",
    "plt.imshow(img_with_keypoints)\n",
    "plt.title(f'SIFT Keypoints ({len(keypoints)} detected)')\n",
    "plt.axis('off')\n",
    "\n",
    "plt.subplot(1, 3, 3)\n",
    "plt.imshow(lena_gray, cmap='gray')\n",
    "x_coords = [kp.pt[0] for kp in keypoints]\n",
    "y_coords = [kp.pt[1] for kp in keypoints]\n",
    "plt.scatter(x_coords, y_coords, c='red', s=10, alpha=0.7)\n",
    "plt.title('SIFT Keypoint Locations')\n",
    "plt.axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79e24245",
   "metadata": {},
   "source": [
    "## 5. Harris Corner Detection / ハリスコーナー検出\n",
    "\n",
    "Harris corner detection finds corners by analyzing the local structure of the image.\n",
    "\n",
    "ハリスコーナー検出は、画像の局所構造を分析してコーナーを見つけます。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1578375",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Harris corner detection\n",
    "harris_corners = cv2.cornerHarris(lena_gray, 2, 3, 0.04)\n",
    "\n",
    "harris_corners = cv2.dilate(harris_corners, None)\n",
    "\n",
    "img_harris = lena_img.copy()\n",
    "img_harris[harris_corners > 0.01 * harris_corners.max()] = [255, 0, 0]\n",
    "\n",
    "coords = feature.corner_peaks(feature.corner_harris(lena_gray), min_distance=5)\n",
    "\n",
    "plt.figure(figsize=(15, 5))\n",
    "\n",
    "plt.subplot(1, 3, 1)\n",
    "plt.imshow(lena_img)\n",
    "plt.title('Original Image')\n",
    "plt.axis('off')\n",
    "\n",
    "plt.subplot(1, 3, 2)\n",
    "plt.imshow(img_harris)\n",
    "plt.title('Harris Corners (OpenCV)')\n",
    "plt.axis('off')\n",
    "\n",
    "plt.subplot(1, 3, 3)\n",
    "plt.imshow(lena_gray, cmap='gray')\n",
    "plt.plot(coords[:, 1], coords[:, 0], 'r+', markersize=8)\n",
    "plt.title(f'Harris Corners (scikit-image): {len(coords)} detected')\n",
    "plt.axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f\"OpenCV Harris corners: {np.sum(harris_corners > 0.01 * harris_corners.max())} detected\")\n",
    "print(f\"Scikit-image Harris corners: {len(coords)} detected\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5dcd0594",
   "metadata": {},
   "source": [
    "## Summary / まとめ\n",
    "\n",
    "In this tutorial, we demonstrated various image filtering techniques:\n",
    "\n",
    "このチュートリアルでは、様々な画像フィルタリング技術を実演しました：\n",
    "\n",
    "\n",
    "1. **Image Download / 画像ダウンロード**: Successfully downloaded and processed the Lena image\n",
    "   レナ画像のダウンロードと処理に成功\n",
    "\n",
    "2. **Smoothing Filters / 平滑化フィルタ**: \n",
    "   - Gaussian blur for noise reduction / ノイズ減少のためのガウシアンぼかし\n",
    "   - Median filter for salt-and-pepper noise / 塩胡椒ノイズのためのメディアンフィルタ\n",
    "\n",
    "3. **Edge Detection / エッジ検出**: \n",
    "   - Sobel filters in X and Y directions / X・Y方向のソーベルフィルタ\n",
    "   - Diagonal edge detection / 対角エッジ検出\n",
    "   - Magnitude and direction computation / 大きさと方向の計算\n",
    "\n",
    "4. **Feature Detection / 特徴検出**: \n",
    "   - SIFT keypoints for scale-invariant features / スケール不変特徴のためのSIFTキーポイント\n",
    "   - Harris corner detection for structural features / 構造的特徴のためのハリスコーナー検出\n",
    "\n",
    "\n",
    "These techniques form the foundation for:\n",
    "- Object recognition and tracking / 物体認識と追跡\n",
    "- Image registration and stitching / 画像レジストレーションと合成\n",
    "- Computer vision preprocessing / コンピュータビジョン前処理\n",
    "- Medical image analysis / 医用画像解析"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
